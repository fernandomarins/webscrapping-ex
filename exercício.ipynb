{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967979d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e866946",
   "metadata": {},
   "source": [
    "### For a single book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ebdc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_book = 'https://books.toscrape.com/catalogue/the-metamorphosis_409/index.html'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5), AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "page = requests.get(url_book, headers=headers)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d31cc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info = soup.find('div', class_='col-sm-6 product_main')\n",
    "\n",
    "book_name = book_info.find('h1').get_text()\n",
    "\n",
    "# dropping the first character because it's garbage\n",
    "book_price = book_info.find('p', class_='price_color').get_text()[1:]\n",
    "\n",
    "# I am using filter to get only value characters\n",
    "# Then splitting using \\n, getting thea second element, which is the stock\n",
    "# Then removing the white spaces before the stock\n",
    "book_stock = list(filter(None, book_info.find('p',\n",
    "                         class_='instock availability').get_text().split('\\n')))[1].strip()\n",
    "\n",
    "# here I am getting all the classes for p and then selecting the last element\n",
    "book_review = [value for element in book_info.find_all('p', class_=True) for value in element[\"class\"]][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2418e0",
   "metadata": {},
   "source": [
    "### For a single category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5efc4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://books.toscrape.com/catalogue/category/books/classics_6/index.html'\n",
    "\n",
    "# the header is added so the request is treated like a web browser\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5), AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ec1f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = soup.find('ol', class_='row')\n",
    "links = books.find_all('div', class_='image_container')\n",
    "\n",
    "full_links = []\n",
    "\n",
    "for l in links:\n",
    "    # building the URLs, removing the first 9 characters of the link since it's gargabe\n",
    "    url = 'https://books.toscrape.com/catalogue/' + str(l.find('a', href=True)['href'][9:])\n",
    "    full_links.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0202af6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book number: 0\n",
      "Book number: 1\n",
      "Book number: 2\n",
      "Book number: 3\n",
      "Book number: 4\n",
      "Book number: 5\n",
      "Book number: 6\n",
      "Book number: 7\n",
      "Book number: 8\n",
      "Book number: 9\n",
      "Book number: 10\n",
      "Book number: 11\n",
      "Book number: 12\n",
      "Book number: 13\n",
      "Book number: 14\n",
      "Book number: 15\n",
      "Book number: 16\n",
      "Book number: 17\n",
      "Book number: 18\n"
     ]
    }
   ],
   "source": [
    "book_names = []\n",
    "book_prices = []\n",
    "book_reviews = []\n",
    "book_stocks = []\n",
    "n = 0\n",
    "\n",
    "for i in full_links:\n",
    "    \n",
    "    print('Book number: {0}'.format(n))\n",
    "    n += 1\n",
    "    url = i\n",
    "\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    book_info = soup.find('div', class_='col-sm-6 product_main')\n",
    "\n",
    "    book_name = book_info.find('h1').get_text()\n",
    "    book_names.append(book_name)\n",
    "\n",
    "    # dropping the first character because it's garbage\n",
    "    book_price = book_info.find('p', class_='price_color').get_text()[1:]\n",
    "    book_prices.append(book_price)\n",
    "\n",
    "    # I am using filter to get only value characters\n",
    "    # Then splitting using \\n, getting thea second element, which is the stock\n",
    "    # Then removing the white spaces before the stock\n",
    "    book_stock = list(filter(None, book_info.find('p',\n",
    "                         class_='instock availability').get_text().split('\\n')))[1].strip()\n",
    "    book_stocks.append(book_stock)\n",
    "\n",
    "    # here I am getting all the classes for p and then selecting the last element\n",
    "    book_review = [value for element in book_info.find_all('p', class_=True) for value in element[\"class\"]][-1]\n",
    "    book_reviews.append(book_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46a45367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Stock</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Secret Garden</td>\n",
       "      <td>£15.08</td>\n",
       "      <td>Four</td>\n",
       "      <td>In stock (5 available)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Metamorphosis</td>\n",
       "      <td>£28.58</td>\n",
       "      <td>One</td>\n",
       "      <td>In stock (5 available)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Pilgrim's Progress</td>\n",
       "      <td>£50.26</td>\n",
       "      <td>Two</td>\n",
       "      <td>In stock (4 available)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Hound of the Baskervilles (Sherlock Holmes...</td>\n",
       "      <td>£14.82</td>\n",
       "      <td>Two</td>\n",
       "      <td>In stock (4 available)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Women (Little Women #1)</td>\n",
       "      <td>£28.07</td>\n",
       "      <td>Four</td>\n",
       "      <td>In stock (4 available)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name   Price Stock  \\\n",
       "0                                  The Secret Garden  £15.08  Four   \n",
       "1                                  The Metamorphosis  £28.58   One   \n",
       "2                             The Pilgrim's Progress  £50.26   Two   \n",
       "3  The Hound of the Baskervilles (Sherlock Holmes...  £14.82   Two   \n",
       "4                     Little Women (Little Women #1)  £28.07  Four   \n",
       "\n",
       "                   Review  \n",
       "0  In stock (5 available)  \n",
       "1  In stock (5 available)  \n",
       "2  In stock (4 available)  \n",
       "3  In stock (4 available)  \n",
       "4  In stock (4 available)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.DataFrame([book_names, book_prices, book_reviews, book_stocks]).T\n",
    "books_df.columns = [['Name', 'Price', 'Stock', 'Review']]\n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64572a1",
   "metadata": {},
   "source": [
    "### For multiple categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052c609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://books.toscrape.com/index.html'\n",
    "\n",
    "# the header is added so the request is treated like a web browser\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5), AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ba1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = soup.find_all('ul', class_='nav nav-list')\n",
    "categories_links = []\n",
    "for i in categories:\n",
    "    all_links = i.find_all('a', href=True)\n",
    "    for l in all_links:\n",
    "        url = 'https://books.toscrape.com/' + l['href']\n",
    "        categories_links.append(url)\n",
    "\n",
    "# getting books only for four categories\n",
    "filtered_links = []\n",
    "filters = ['classics_6', 'science-fiction_16', 'humor_30', 'business_35']\n",
    "# for loop in all links\n",
    "for l in categories_links:\n",
    "    # for loop in the filters\n",
    "    for f in filters:\n",
    "        # if the filter is present in the link, add the link to the list\n",
    "        if f in l:\n",
    "            filtered_links.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f437bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = ''\n",
    "for link in filtered_links:\n",
    "    if 'classics_6' in link:\n",
    "        category = 'Classics'\n",
    "    elif 'science-fiction_16' in link:\n",
    "        category = 'Science Fiction'\n",
    "    elif 'humor_30' in link:\n",
    "        category = 'Humor'\n",
    "    else:\n",
    "        category = 'Business'\n",
    "        \n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c288ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.DataFrame()\n",
    "\n",
    "n = 0\n",
    "\n",
    "for link in filtered_links:\n",
    "    \n",
    "    url = link\n",
    "\n",
    "    # the header is added so the request is treated like a web browser\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5), AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    books = soup.find('ol', class_='row')\n",
    "    links = books.find_all('div', class_='image_container')\n",
    "\n",
    "    full_links = []\n",
    "\n",
    "    for l in links:\n",
    "        # building the URLs, removing the first 9 characters of the link since it's gargabe\n",
    "        url = 'https://books.toscrape.com/catalogue/' + str(l.find('a', href=True)['href'][9:])\n",
    "        full_links.append(url)\n",
    "        \n",
    "    book_names = []\n",
    "    book_prices = []\n",
    "    book_reviews = []\n",
    "    book_stocks = []\n",
    "    book_category = []\n",
    "    \n",
    "    # added this if clauses here to change the category\n",
    "    if 'classics_6' in link:\n",
    "        category = 'Classics'\n",
    "    elif 'science-fiction_16' in link:\n",
    "        category = 'Science Fiction'\n",
    "    elif 'humor_30' in link:\n",
    "        category = 'Humor'\n",
    "    else:\n",
    "        category = 'Business'\n",
    "\n",
    "    for i in full_links:\n",
    "        url = i\n",
    "        \n",
    "        print('Book number: {0}'.format(n))\n",
    "        n += 1\n",
    "\n",
    "        page = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "        book_info = soup.find('div', class_='col-sm-6 product_main')\n",
    "\n",
    "        book_name = book_info.find('h1').get_text()\n",
    "        book_names.append(book_name)\n",
    "\n",
    "        # dropping the first character because it's garbage\n",
    "        book_price = book_info.find('p', class_='price_color').get_text()[1:]\n",
    "        book_prices.append(book_price)\n",
    "\n",
    "        # I am using filter to get only value characters\n",
    "        # Then splitting using \\n, getting thea second element, which is the stock\n",
    "        # Then removing the white spaces before the stock\n",
    "        book_stock = list(filter(None, book_info.find('p',\n",
    "                         class_='instock availability').get_text().split('\\n')))[1].strip()\n",
    "        book_stocks.append(book_stock)\n",
    "\n",
    "        # here I am getting all the classes for p and then selecting the last element\n",
    "        book_review = [value for element in book_info.find_all('p', class_=True) for value in element[\"class\"]][-1]\n",
    "        book_reviews.append(book_review)\n",
    "        \n",
    "        book_category.append(category)\n",
    "    \n",
    "    books_df = pd.DataFrame([book_names, book_prices, book_reviews, book_category, book_stocks]).T\n",
    "    \n",
    "    data_raw = pd.concat([data_raw, books_df], axis=0)\n",
    "    \n",
    "data_raw.columns = [['Name', 'Price', 'Stock', 'Category', 'Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219fefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.to_csv('books.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1dcae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
